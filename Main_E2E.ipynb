{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfd2cbbc492545d18a40671d41169a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_861f007038bc4f7a959e9b99b28ddadf",
              "IPY_MODEL_37c73e877ad047c2aeee3092e44353b4",
              "IPY_MODEL_d730c5ae8761452284506f6e2fbeb662"
            ],
            "layout": "IPY_MODEL_06ad345c4e4a49e08535fcb5c168a8dd"
          }
        },
        "861f007038bc4f7a959e9b99b28ddadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f587d9bc7e4ea4bbaa58b1c192da8d",
            "placeholder": "​",
            "style": "IPY_MODEL_a435df86395b452eb94b8dd1a1012808",
            "value": "config.json: 100%"
          }
        },
        "37c73e877ad047c2aeee3092e44353b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7813e0c1f8014d14a7a021aac953daee",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf28418e6c147d4b609ef8381c43f9c",
            "value": 665
          }
        },
        "d730c5ae8761452284506f6e2fbeb662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a889f4732d546e99e48721ae69ab85c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b824c843f9940aea702e2b13f649f86",
            "value": " 665/665 [00:00&lt;00:00, 7.61kB/s]"
          }
        },
        "06ad345c4e4a49e08535fcb5c168a8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f587d9bc7e4ea4bbaa58b1c192da8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a435df86395b452eb94b8dd1a1012808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7813e0c1f8014d14a7a021aac953daee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf28418e6c147d4b609ef8381c43f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a889f4732d546e99e48721ae69ab85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b824c843f9940aea702e2b13f649f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83394d1b26504f4994d55b4ea5d2862f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1d773085efa43df95db24659ecc6267",
              "IPY_MODEL_94a6754cf1904a82aa51bb20c86a33fe",
              "IPY_MODEL_33e63920dba24fe0a5cdf53a9d6cdbfc"
            ],
            "layout": "IPY_MODEL_930347a884e24b0683a000b340eeae97"
          }
        },
        "d1d773085efa43df95db24659ecc6267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78ff8f07fdba49039534b8b5f8ecb3c9",
            "placeholder": "​",
            "style": "IPY_MODEL_d45456cc284c43039811ccac3e11e0a4",
            "value": "vocab.json: 100%"
          }
        },
        "94a6754cf1904a82aa51bb20c86a33fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ef01ec446f43e19bfe755e8f9e32c6",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_581117257a4542d58b53302b6e3473c5",
            "value": 1042301
          }
        },
        "33e63920dba24fe0a5cdf53a9d6cdbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44910b4c507c4b53a6aa3234dbfa8783",
            "placeholder": "​",
            "style": "IPY_MODEL_78107ee88ca14c4b8f26e822f362843c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.10MB/s]"
          }
        },
        "930347a884e24b0683a000b340eeae97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ff8f07fdba49039534b8b5f8ecb3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45456cc284c43039811ccac3e11e0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ef01ec446f43e19bfe755e8f9e32c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581117257a4542d58b53302b6e3473c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44910b4c507c4b53a6aa3234dbfa8783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78107ee88ca14c4b8f26e822f362843c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcacf92f12f84a15bc40fd1af6d342d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7229fae52dc842469a5a5cad47a56fba",
              "IPY_MODEL_853590fce05c409e8e1b49350cf2cebc",
              "IPY_MODEL_59fca4dedcb043a49e444ac3d6c36806"
            ],
            "layout": "IPY_MODEL_cf5ba4c0f4e84452a1b36f9bbae7d17a"
          }
        },
        "7229fae52dc842469a5a5cad47a56fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9768f884993c4de6935470deee1961d1",
            "placeholder": "​",
            "style": "IPY_MODEL_e59ff718ca4e4151b776d9228d3a3e20",
            "value": "merges.txt: 100%"
          }
        },
        "853590fce05c409e8e1b49350cf2cebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34095f2eb7b4d1e85d5d16b0b2e7232",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5f6f10f08524bec897cf324e30697d4",
            "value": 456318
          }
        },
        "59fca4dedcb043a49e444ac3d6c36806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b985a08dc0564ba8ac5bf073bea8123c",
            "placeholder": "​",
            "style": "IPY_MODEL_3af1824501294898a4b891eb26e8214a",
            "value": " 456k/456k [00:00&lt;00:00, 935kB/s]"
          }
        },
        "cf5ba4c0f4e84452a1b36f9bbae7d17a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9768f884993c4de6935470deee1961d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59ff718ca4e4151b776d9228d3a3e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d34095f2eb7b4d1e85d5d16b0b2e7232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f6f10f08524bec897cf324e30697d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b985a08dc0564ba8ac5bf073bea8123c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af1824501294898a4b891eb26e8214a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a2b6247fd342f69c3be9bf8c61ef35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8455d7cb5da34672ae6b2e4c3e3fead0",
              "IPY_MODEL_adb46ee900534f77b2d58d990400ddc0",
              "IPY_MODEL_ac2556116e134847a54105facc093dc1"
            ],
            "layout": "IPY_MODEL_80a8dc80ce9f46f4b302da9c7aa93219"
          }
        },
        "8455d7cb5da34672ae6b2e4c3e3fead0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b51700d016046c1a031e8f3a1b530ca",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d74d3b98e042d286eff5fd635beb4d",
            "value": "tokenizer.json: 100%"
          }
        },
        "adb46ee900534f77b2d58d990400ddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9d0de1dfa44d72ae73075e38a5f344",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da7934b4c6da4ba58a1f399bdcf3c259",
            "value": 1355256
          }
        },
        "ac2556116e134847a54105facc093dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbfde8ed1d546ef9fbff1920725b383",
            "placeholder": "​",
            "style": "IPY_MODEL_755d68ee63f14b0e9a03d97446c56f83",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.15MB/s]"
          }
        },
        "80a8dc80ce9f46f4b302da9c7aa93219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b51700d016046c1a031e8f3a1b530ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d74d3b98e042d286eff5fd635beb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb9d0de1dfa44d72ae73075e38a5f344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7934b4c6da4ba58a1f399bdcf3c259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bbfde8ed1d546ef9fbff1920725b383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755d68ee63f14b0e9a03d97446c56f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M49fSPouYUS0",
        "outputId": "baa8e43b-c868-49da-effc-441581e6c547"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#used these versions since they where used by the differential private finetuning code\n",
        "!pip install opacus==0.15.0\n",
        "#!pip install torch==1.11.0\n",
        "!pip install datasets\n",
        "!pip install loralib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyT2tTO3-rrH",
        "outputId": "b59f4341-25ec-4573-a562-62ec74fa2341"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus==0.15.0\n",
            "  Downloading opacus-0.15.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus==0.15.0) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from opacus==0.15.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus==0.15.0) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->opacus==0.15.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->opacus==0.15.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->opacus==0.15.0) (1.3.0)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-0.15.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n",
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nqq3o2Me-b53"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, get_scheduler, DataCollatorForLanguageModeling\n",
        "from opacus import PrivacyEngine\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "#######################\n",
        "import os\n",
        "from os.path import join, abspath, dirname\n",
        "from data_utils.dataset import load_file, LAMADataset\n",
        "from data_utils.vocab import init_vocab\n",
        "from p_tune.modeling import PTuneForLAMA\n",
        "from transformers import AutoTokenizer\n",
        "#############################\n",
        "from loralib import MergedLinear\n",
        "import loralib as lora\n",
        "from opacus.grad_sample import utils as opacus_utils\n",
        "from opacus.layers import DPLSTM\n",
        "from tqdm import tqdm\n",
        "from src.model import GPT2Config, GPT2LMModel\n",
        "from src.data_utils import FT_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functions used in this code\n",
        "def get_task_name():\n",
        "        if args.only_evaluate:\n",
        "            return \"_\".join([args.model_name + ('_' + args.vocab_strategy), 'only_evaluate'])\n",
        "        names = [args.model_name + ('_' + args.vocab_strategy),\n",
        "                 \"template_{}\".format(args.template if not args.use_original_template else 'original'),\n",
        "                 \"fixed\" if not args.use_lm_finetune else \"fine-tuned\",\n",
        "                 \"seed_{}\".format(args.seed)]\n",
        "        return \"_\".join(names)\n",
        "\n",
        "def get_TREx_parameters():\n",
        "        relation = load_file(join(args.data_dir, \"single_relations/{}.jsonl\".format(args.relation_id)))[0]\n",
        "        data_path_pre = \"fact-retrieval/original/{}/\".format(args.relation_id)\n",
        "        data_path_post = \".jsonl\"\n",
        "        return relation, data_path_pre, data_path_post\n",
        "def get_save_path():\n",
        "        return join(args.out_dir, 'prompt_model', args.model_name, 'search', get_task_name(),\n",
        "                    args.relation_id)\n",
        "\n",
        "def reverse_zero_pad(x, W, enable_lora, out_features):\n",
        "    lora_ind = W.new_zeros((out_features, ), dtype=torch.bool).view(len(enable_lora), -1)\n",
        "    lora_ind[enable_lora, :] = True\n",
        "    lora_ind = lora_ind.view(-1)\n",
        "    result = x.new_zeros((*x.shape[:-1], out_features // len(enable_lora) * sum(enable_lora)))\n",
        "    result = result.view(-1, out_features // len(enable_lora) * sum(enable_lora))\n",
        "    result = x.reshape(-1, out_features)[:, lora_ind]\n",
        "    return result.view((*x.shape[:-1], out_features // len(enable_lora) * sum(enable_lora)))\n",
        "\n",
        "\n",
        "def compute_transformers_MergedLinear_grad_sample(layer: MergedLinear, A: torch.Tensor, B: torch.Tensor, batch_dim: int = 0) -> None:\n",
        "    delta1 = reverse_zero_pad(B, layer.weight, layer.enable_lora, layer.out_features) * layer.scaling\n",
        "    after_A = F.linear(layer.lora_dropout(A), layer.lora_A)\n",
        "    t_after_A = after_A.transpose(-2, -1)\n",
        "    in_channel = t_after_A.shape[1]\n",
        "    out_channel = delta1.shape[-1]\n",
        "    lora_b_channel = layer.lora_B.shape[0]\n",
        "\n",
        "    gs1 = torch.einsum(\"nik,nkj->nij\", t_after_A[:, :in_channel//2, :], delta1[:, :, :out_channel//2])\n",
        "    gs2 = torch.einsum(\"nik,nkj->nij\", t_after_A[:, in_channel//2:, :], delta1[:, :, out_channel//2:])\n",
        "    opacus_utils.create_or_extend_grad_sample(layer.lora_B, torch.cat((gs1, gs2), -1).transpose(-2,-1).contiguous(), batch_dim)\n",
        "    gs3 = torch.einsum(\"nik,kj->nij\", delta1[:, :, :out_channel//2], layer.lora_B[:lora_b_channel//2, :])\n",
        "    gs4 = torch.einsum(\"nik,kj->nij\", delta1[:, :, out_channel//2:], layer.lora_B[lora_b_channel//2:, :])\n",
        "    after_A_deriv = torch.cat((gs3, gs4), -1)\n",
        "    lora_A_deriv = torch.einsum(\"nki,nkj->nij\", after_A_deriv, layer.lora_dropout(A))\n",
        "    opacus_utils.create_or_extend_grad_sample(layer.lora_A, lora_A_deriv.contiguous(), batch_dim)\n",
        "\n",
        "def evaluate(epoch_idx, evaluate_type):\n",
        "        model.eval()\n",
        "        if evaluate_type == 'Test':\n",
        "            loader = test_loader\n",
        "            dataset = test_set\n",
        "        else:\n",
        "            loader = dev_loader\n",
        "            dataset = dev_set\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            hit1, loss = 0, 0\n",
        "            for x_hs, x_ts in loader:\n",
        "                if False and self.args.extend_data:\n",
        "                    _loss, _hit1 = self.model.test_extend_data(x_hs, x_ts)\n",
        "                elif evaluate_type == 'Test':\n",
        "                    _loss, _hit1, top10 = model(x_hs, x_ts, return_candidates=True)\n",
        "                else:\n",
        "                    _loss, _hit1 = model(x_hs, x_ts)\n",
        "                hit1 += _hit1\n",
        "                loss += _loss.item()\n",
        "            hit1 /= len(dataset)\n",
        "            print(\"{} {} Epoch {} Loss: {} Hit@1:\".format(args.relation_id, evaluate_type, epoch_idx,\n",
        "                                                          loss / len(dataset)), hit1)\n",
        "        return loss, hit1\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "         Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "K6CrsdpnY7-C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    init_checkpoint = \"/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2/pretrained_checkpoints/gpt2-pytorch_model.bin\"\n",
        "    learning_rate = 2e-5\n",
        "    train_batch_size = 8\n",
        "    valid_batch_size = 4\n",
        "    grad_acc_steps = 1\n",
        "    epochs = 3\n",
        "    noise_multiplier = 1.0\n",
        "    max_grad_norm = 1.0\n",
        "    lstm_dropout = 0.1\n",
        "    hidden_size = 768\n",
        "    max_length = 128\n",
        "\n",
        "    relation_id = \"P1001\"\n",
        "    model_name = 'gpt2'\n",
        "    pseudo_token = '[PROMPT]'\n",
        "\n",
        "    t5_shard = 0\n",
        "    mid = 0\n",
        "    template = (3, 3, 3)\n",
        "    early_stop = 20\n",
        "\n",
        "    lr = 1e-5\n",
        "    seed = 34\n",
        "    decay_rate = 0.98\n",
        "    weight_decay = 0.0005\n",
        "    no_cuda = False\n",
        "    seq_len = 128\n",
        "\n",
        "\n",
        "    only_evaluate = False\n",
        "    use_original_template = False\n",
        "    use_lm_finetune = False\n",
        "\n",
        "    vocab_strategy = \"original\"\n",
        "\n",
        "    train_data = '/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2/data/e2e/train.jsonl'\n",
        "    valid_data = '/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2/data/e2e/valid.jsonl'\n",
        "\n",
        "    # directories\n",
        "    data_dir = '/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2/data/LAMA'\n",
        "    out_dir = '/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/Language-Generation-GPT-2/out/LAMA'\n",
        "\n",
        "\n",
        "    lora_dim = 4\n",
        "    lora_alpha = 32\n",
        "    lora_dropout = 0.0\n",
        "    label_smooth = 0.1\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    n_gpu = 0 if no_cuda else torch.cuda.device_count()\n",
        "\n",
        "    assert isinstance(template, tuple)\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "oGvNDM-cgOFg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer init\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2', use_fast=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "dfd2cbbc492545d18a40671d41169a9a",
            "861f007038bc4f7a959e9b99b28ddadf",
            "37c73e877ad047c2aeee3092e44353b4",
            "d730c5ae8761452284506f6e2fbeb662",
            "06ad345c4e4a49e08535fcb5c168a8dd",
            "f1f587d9bc7e4ea4bbaa58b1c192da8d",
            "a435df86395b452eb94b8dd1a1012808",
            "7813e0c1f8014d14a7a021aac953daee",
            "baf28418e6c147d4b609ef8381c43f9c",
            "4a889f4732d546e99e48721ae69ab85c",
            "4b824c843f9940aea702e2b13f649f86",
            "83394d1b26504f4994d55b4ea5d2862f",
            "d1d773085efa43df95db24659ecc6267",
            "94a6754cf1904a82aa51bb20c86a33fe",
            "33e63920dba24fe0a5cdf53a9d6cdbfc",
            "930347a884e24b0683a000b340eeae97",
            "78ff8f07fdba49039534b8b5f8ecb3c9",
            "d45456cc284c43039811ccac3e11e0a4",
            "d8ef01ec446f43e19bfe755e8f9e32c6",
            "581117257a4542d58b53302b6e3473c5",
            "44910b4c507c4b53a6aa3234dbfa8783",
            "78107ee88ca14c4b8f26e822f362843c",
            "bcacf92f12f84a15bc40fd1af6d342d1",
            "7229fae52dc842469a5a5cad47a56fba",
            "853590fce05c409e8e1b49350cf2cebc",
            "59fca4dedcb043a49e444ac3d6c36806",
            "cf5ba4c0f4e84452a1b36f9bbae7d17a",
            "9768f884993c4de6935470deee1961d1",
            "e59ff718ca4e4151b776d9228d3a3e20",
            "d34095f2eb7b4d1e85d5d16b0b2e7232",
            "e5f6f10f08524bec897cf324e30697d4",
            "b985a08dc0564ba8ac5bf073bea8123c",
            "3af1824501294898a4b891eb26e8214a",
            "03a2b6247fd342f69c3be9bf8c61ef35",
            "8455d7cb5da34672ae6b2e4c3e3fead0",
            "adb46ee900534f77b2d58d990400ddc0",
            "ac2556116e134847a54105facc093dc1",
            "80a8dc80ce9f46f4b302da9c7aa93219",
            "6b51700d016046c1a031e8f3a1b530ca",
            "e9d74d3b98e042d286eff5fd635beb4d",
            "eb9d0de1dfa44d72ae73075e38a5f344",
            "da7934b4c6da4ba58a1f399bdcf3c259",
            "1bbfde8ed1d546ef9fbff1920725b383",
            "755d68ee63f14b0e9a03d97446c56f83"
          ]
        },
        "id": "hiNsBRUJYxVS",
        "outputId": "743df3b9-e3c1-4136-96c3-02e2afef6184"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfd2cbbc492545d18a40671d41169a9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83394d1b26504f4994d55b4ea5d2862f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcacf92f12f84a15bc40fd1af6d342d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03a2b6247fd342f69c3be9bf8c61ef35"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = FT_Dataset(\n",
        "    args.train_data, args.train_batch_size, args.seq_len,\n",
        "    #    joint_lm=args.obj=='jlm'\n",
        ")\n",
        "\n",
        "valid_data = FT_Dataset(\n",
        "    args.valid_data, args.valid_batch_size, args.seq_len,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data, batch_size=args.train_batch_size, num_workers=0,\n",
        "    shuffle=False, pin_memory=False, drop_last=True,\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_data, batch_size=args.valid_batch_size, num_workers=0,\n",
        "    shuffle=False, pin_memory=False, drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "GQm2tSL1tple"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPT2Config(\n",
        "    n_embd=768, n_layer=12, n_head=12,\n",
        "    lora_attn_dim=args.lora_dim,\n",
        "    lora_attn_alpha=args.lora_alpha,\n",
        "    lora_dropout=args.lora_dropout,\n",
        ")\n",
        "model = GPT2LMModel(config)\n",
        "#model.to(args.device)\n",
        "\n",
        "if args.init_checkpoint is not None:\n",
        "        print('loading model pretrained weight.')\n",
        "        model.load_weight(torch.load(args.init_checkpoint))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzzCxELeZGz7",
        "outputId": "c4f6c12b-2a5c-4959-aded-c4b7565ef362"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model pretrained weight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptEncoder(torch.nn.Module):\n",
        "    def __init__(self, template, hidden_size, tokenizer, device, args):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.spell_length = sum(template)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.args = args\n",
        "        # ent embedding\n",
        "        self.cloze_length = template\n",
        "        self.cloze_mask = [\n",
        "            [1] * self.cloze_length[0]  # first cloze\n",
        "            + [1] * self.cloze_length[1]  # second cloze\n",
        "            + [1] * self.cloze_length[2]  # third cloze\n",
        "        ]\n",
        "        self.cloze_mask = torch.LongTensor(self.cloze_mask).bool().to(self.device)\n",
        "\n",
        "        self.seq_indices = torch.LongTensor(list(range(len(self.cloze_mask[0])))).to(self.device)\n",
        "        # embedding\n",
        "        self.embedding = torch.nn.Embedding(len(self.cloze_mask[0]), self.hidden_size).to(self.device)\n",
        "        # LSTM\n",
        "        self.lstm_head = torch.nn.LSTM(input_size=self.hidden_size,\n",
        "                                       hidden_size=self.hidden_size // 2,\n",
        "                                       num_layers=2,\n",
        "                                       dropout=self.args.lstm_dropout,\n",
        "                                       bidirectional=True,\n",
        "                                       batch_first=True)\n",
        "        self.lstm_head = DPLSTM(input_size=self.hidden_size,\n",
        "                                       hidden_size=self.hidden_size // 2,\n",
        "                                       num_layers=2,\n",
        "                                       dropout=self.args.lstm_dropout,\n",
        "                                       bidirectional=True,\n",
        "                                       batch_first=True)\n",
        "        self.mlp_head = nn.Sequential(nn.Linear(self.hidden_size, self.hidden_size),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.Linear(self.hidden_size, self.hidden_size))\n",
        "        print(\"init prompt encoder...\")\n",
        "\n",
        "    def forward(self):\n",
        "        input_embeds = self.embedding(self.seq_indices).unsqueeze(0)\n",
        "        output_embeds = self.mlp_head(self.lstm_head(input_embeds)[0]).squeeze()\n",
        "        return output_embeds"
      ],
      "metadata": {
        "id": "KBH4fSLux8ny"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2ModelWithSoftPrompts(torch.nn.Module):\n",
        "    def __init__(self, model, template, hidden_size, tokenizer, device, args):\n",
        "        super().__init__()\n",
        "        self.model = model.to(device)\n",
        "        # Create an instance of PromptEncoder\n",
        "        template = (template[0], template[1], 0)\n",
        "        self.template = template\n",
        "        self.prompt_encoder = PromptEncoder(self.template, hidden_size, tokenizer, device, args)\n",
        "        self.prompt_encoder = self.prompt_encoder.to(device)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, target):\n",
        "        # Generate the dynamic prompt embeddings using the PromptEncoder\n",
        "        prompt_embeddings = self.prompt_encoder().to(args.device)\n",
        "        #print(prompt_embeddings.shape)\n",
        "        # The prompt_embeddings are expected to have a shape of (batch_size, num_prompt_tokens, hidden_size)\n",
        "        # Ensure that the prompt_embeddings are properly shaped before concatenation\n",
        "        prompt_embeddings = prompt_embeddings.unsqueeze(0).repeat(input_ids.shape[0], 1, 1).to(args.device)\n",
        "        #print(prompt_embeddings.shape)\n",
        "        # Concatenate the prompt embeddings with the original token embeddings\n",
        "        inputs_embeds = torch.cat((prompt_embeddings, self.model.transformer.wte(input_ids)), dim=1).to(args.device)\n",
        "\n",
        "        #print(inputs_embeds.shape)\n",
        "\n",
        "        # Adjust attention_mask for the added prompts\n",
        "        prompt_attention_mask = torch.ones((attention_mask.shape[0], prompt_embeddings.shape[1]), device=attention_mask.device).to(args.device)\n",
        "        full_attention_mask = torch.cat((prompt_attention_mask, attention_mask), dim=1).to(args.device)\n",
        "\n",
        "        # Process through the model\n",
        "        outputs = self.model(inputs_embeds=inputs_embeds, attention_mask=full_attention_mask, labels=target)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "sp_model = GPT2ModelWithSoftPrompts(model, args.template, 768, tokenizer, args.device, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Ksqhnwiorb",
        "outputId": "28e51fde-c522-4e6b-9293-6914ab8110e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init prompt encoder...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.lora_dim > 0:\n",
        "      lora.mark_only_lora_as_trainable(model)\n",
        "opacus_utils.register_grad_sampler(MergedLinear)(compute_transformers_MergedLinear_grad_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8e2rvWYVSQ7",
        "outputId": "a5758dc9-76c6-49b3-fdf4-d46ac1c3cc01"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.compute_transformers_MergedLinear_grad_sample(layer: loralib.layers.MergedLinear, A: torch.Tensor, B: torch.Tensor, batch_dim: int = 0) -> None>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_optimize = []\n",
        "for name, param in sp_model.prompt_encoder.named_parameters():\n",
        "    if name == \"embedding.weight\":\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = True\n",
        "\n",
        "    if param.requires_grad:\n",
        "            params_to_optimize.append({'params': param})\n",
        "            #print(name)\n",
        "\n",
        "for param in sp_model.model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "for name, param in sp_model.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "LckDzgfxUZnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b270be-7412-46b8-ed9a-95617e6ba952"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_encoder.embedding.weight\n",
            "prompt_encoder.lstm_head.weight_ih_l0\n",
            "prompt_encoder.lstm_head.bias_ih_l0\n",
            "prompt_encoder.lstm_head.weight_hh_l0\n",
            "prompt_encoder.lstm_head.bias_hh_l0\n",
            "prompt_encoder.lstm_head.weight_ih_l0_reverse\n",
            "prompt_encoder.lstm_head.bias_ih_l0_reverse\n",
            "prompt_encoder.lstm_head.weight_hh_l0_reverse\n",
            "prompt_encoder.lstm_head.bias_hh_l0_reverse\n",
            "prompt_encoder.lstm_head.weight_ih_l1\n",
            "prompt_encoder.lstm_head.bias_ih_l1\n",
            "prompt_encoder.lstm_head.weight_hh_l1\n",
            "prompt_encoder.lstm_head.bias_hh_l1\n",
            "prompt_encoder.lstm_head.weight_ih_l1_reverse\n",
            "prompt_encoder.lstm_head.bias_ih_l1_reverse\n",
            "prompt_encoder.lstm_head.weight_hh_l1_reverse\n",
            "prompt_encoder.lstm_head.bias_hh_l1_reverse\n",
            "prompt_encoder.mlp_head.0.weight\n",
            "prompt_encoder.mlp_head.0.bias\n",
            "prompt_encoder.mlp_head.2.weight\n",
            "prompt_encoder.mlp_head.2.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params_to_optimize, lr=args.lr, weight_decay=args.weight_decay)"
      ],
      "metadata": {
        "id": "h3EYlW1fYHGi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attaching the privacy engine\n",
        "ALPHAS = [1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64))\n",
        "SAMPLE_RATE = (args.train_batch_size * args.grad_acc_steps)/42061.0\n",
        "privacy_engine = PrivacyEngine(\n",
        "    module=model,\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    alphas=ALPHAS,\n",
        "    noise_multiplier=args.noise_multiplier,\n",
        "    max_grad_norm=args.max_grad_norm,\n",
        ")\n",
        "privacy_engine.attach(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "CAXmGLm-Z_pq",
        "outputId": "bcd09d33-bb45-44f7-858f-fec80ccfe788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:759: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:236: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IncompatibleModuleException",
          "evalue": "Model contains incompatible modules.\ngrad_sampler method is not yet supported for this module.: ['_module.transformer.h.0.attn.c_attn (Conv1D)', '_module.transformer.h.0.attn.c_proj (Conv1D)', '_module.transformer.h.0.mlp.c_fc (Conv1D)', '_module.transformer.h.0.mlp.c_proj (Conv1D)', '_module.transformer.h.1.attn.c_attn (Conv1D)', '_module.transformer.h.1.attn.c_proj (Conv1D)', '_module.transformer.h.1.mlp.c_fc (Conv1D)', '_module.transformer.h.1.mlp.c_proj (Conv1D)', '_module.transformer.h.2.attn.c_attn (Conv1D)', '_module.transformer.h.2.attn.c_proj (Conv1D)', '_module.transformer.h.2.mlp.c_fc (Conv1D)', '_module.transformer.h.2.mlp.c_proj (Conv1D)', '_module.transformer.h.3.attn.c_attn (Conv1D)', '_module.transformer.h.3.attn.c_proj (Conv1D)', '_module.transformer.h.3.mlp.c_fc (Conv1D)', '_module.transformer.h.3.mlp.c_proj (Conv1D)', '_module.transformer.h.4.attn.c_attn (Conv1D)', '_module.transformer.h.4.attn.c_proj (Conv1D)', '_module.transformer.h.4.mlp.c_fc (Conv1D)', '_module.transformer.h.4.mlp.c_proj (Conv1D)', '_module.transformer.h.5.attn.c_attn (Conv1D)', '_module.transformer.h.5.attn.c_proj (Conv1D)', '_module.transformer.h.5.mlp.c_fc (Conv1D)', '_module.transformer.h.5.mlp.c_proj (Conv1D)', '_module.transformer.h.6.attn.c_attn (Conv1D)', '_module.transformer.h.6.attn.c_proj (Conv1D)', '_module.transformer.h.6.mlp.c_fc (Conv1D)', '_module.transformer.h.6.mlp.c_proj (Conv1D)', '_module.transformer.h.7.attn.c_attn (Conv1D)', '_module.transformer.h.7.attn.c_proj (Conv1D)', '_module.transformer.h.7.mlp.c_fc (Conv1D)', '_module.transformer.h.7.mlp.c_proj (Conv1D)', '_module.transformer.h.8.attn.c_attn (Conv1D)', '_module.transformer.h.8.attn.c_proj (Conv1D)', '_module.transformer.h.8.mlp.c_fc (Conv1D)', '_module.transformer.h.8.mlp.c_proj (Conv1D)', '_module.transformer.h.9.attn.c_attn (Conv1D)', '_module.transformer.h.9.attn.c_proj (Conv1D)', '_module.transformer.h.9.mlp.c_fc (Conv1D)', '_module.transformer.h.9.mlp.c_proj (Conv1D)', '_module.transformer.h.10.attn.c_attn (Conv1D)', '_module.transformer.h.10.attn.c_proj (Conv1D)', '_module.transformer.h.10.mlp.c_fc (Conv1D)', '_module.transformer.h.10.mlp.c_proj (Conv1D)', '_module.transformer.h.11.attn.c_attn (Conv1D)', '_module.transformer.h.11.attn.c_proj (Conv1D)', '_module.transformer.h.11.mlp.c_fc (Conv1D)', '_module.transformer.h.11.mlp.c_proj (Conv1D)']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIncompatibleModuleException\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fb6e5f6b197b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprivacy_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py\u001b[0m in \u001b[0;36mattach\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         norm_clipper = (\n\u001b[1;32m    309\u001b[0m             \u001b[0mclipping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstantFlatClipper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opacus/dp_model_inspector.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n{inspector.message}: {inspector.violators}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompatibleModuleException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIncompatibleModuleException\u001b[0m: Model contains incompatible modules.\ngrad_sampler method is not yet supported for this module.: ['_module.transformer.h.0.attn.c_attn (Conv1D)', '_module.transformer.h.0.attn.c_proj (Conv1D)', '_module.transformer.h.0.mlp.c_fc (Conv1D)', '_module.transformer.h.0.mlp.c_proj (Conv1D)', '_module.transformer.h.1.attn.c_attn (Conv1D)', '_module.transformer.h.1.attn.c_proj (Conv1D)', '_module.transformer.h.1.mlp.c_fc (Conv1D)', '_module.transformer.h.1.mlp.c_proj (Conv1D)', '_module.transformer.h.2.attn.c_attn (Conv1D)', '_module.transformer.h.2.attn.c_proj (Conv1D)', '_module.transformer.h.2.mlp.c_fc (Conv1D)', '_module.transformer.h.2.mlp.c_proj (Conv1D)', '_module.transformer.h.3.attn.c_attn (Conv1D)', '_module.transformer.h.3.attn.c_proj (Conv1D)', '_module.transformer.h.3.mlp.c_fc (Conv1D)', '_module.transformer.h.3.mlp.c_proj (Conv1D)', '_module.transformer.h.4.attn.c_attn (Conv1D)', '_module.transformer.h.4.attn.c_proj (Conv1D)', '_module.transformer.h.4.mlp.c_fc (Conv1D)', '_module.transformer.h.4.mlp.c_proj (Conv1D)', '_module.transformer.h.5.attn.c_attn (Conv1D)', '_module.transformer.h.5.attn.c_proj (Conv1D)', '_module.transformer.h.5.mlp.c_fc (Conv1D)', '_module.transformer.h.5.mlp.c_proj (Conv1D)', '_module.transformer.h.6.attn.c_attn (Conv1D)', '_module.transformer.h.6.attn.c_proj (Conv1D)', '_module.transformer.h.6.mlp.c_fc (Conv1D)', '_module.transformer.h.6.mlp.c_proj (Conv1D)', '_module.transformer.h.7.attn.c_attn (Conv1D)', '_module.transformer.h.7.attn.c_proj (Conv1D)', '_module.transformer.h.7...."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if privacy engine is attached - for debug\n",
        "if hasattr(optimizer, \"privacy_engine\"):\n",
        "    print(\"PrivacyEngine is attached.\")\n",
        "    is_attached = isinstance(optimizer.privacy_engine, PrivacyEngine)\n",
        "    print(f\"PrivacyEngine is correctly attached: {is_attached}\")\n",
        "else:\n",
        "    print(\"PrivacyEngine is NOT attached.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVzZb4b2leMO",
        "outputId": "dbf841fc-01a9-4873-8283-1496e64baf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrivacyEngine is NOT attached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss"
      ],
      "metadata": {
        "id": "vCE3e3i29kJT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in sp_model.named_parameters():\n",
        "    if not param.requires_grad:\n",
        "        print(f\"Parameter name: {name} is frozen (not trainable).\")\n",
        "    else: print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIN_rJnkKwkC",
        "outputId": "6b4e4970-a011-4ebb-a727-c71e9222f23e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: model.transformer.wte.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.wpe.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.0.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.1.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.2.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.3.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.4.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.5.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.6.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.7.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.8.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.9.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.10.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.ln_1.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.ln_1.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_attn.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_attn.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_attn.lora_A is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_attn.lora_B is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.attn.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.ln_2.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.ln_2.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.mlp.c_fc.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.mlp.c_fc.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.mlp.c_proj.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.h.11.mlp.c_proj.bias is frozen (not trainable).\n",
            "Parameter name: model.transformer.ln_f.weight is frozen (not trainable).\n",
            "Parameter name: model.transformer.ln_f.bias is frozen (not trainable).\n",
            "prompt_encoder.embedding.weight\n",
            "prompt_encoder.lstm_head.weight_ih_l0\n",
            "prompt_encoder.lstm_head.bias_ih_l0\n",
            "prompt_encoder.lstm_head.weight_hh_l0\n",
            "prompt_encoder.lstm_head.bias_hh_l0\n",
            "prompt_encoder.lstm_head.weight_ih_l0_reverse\n",
            "prompt_encoder.lstm_head.bias_ih_l0_reverse\n",
            "prompt_encoder.lstm_head.weight_hh_l0_reverse\n",
            "prompt_encoder.lstm_head.bias_hh_l0_reverse\n",
            "prompt_encoder.lstm_head.weight_ih_l1\n",
            "prompt_encoder.lstm_head.bias_ih_l1\n",
            "prompt_encoder.lstm_head.weight_hh_l1\n",
            "prompt_encoder.lstm_head.bias_hh_l1\n",
            "prompt_encoder.lstm_head.weight_ih_l1_reverse\n",
            "prompt_encoder.lstm_head.bias_ih_l1_reverse\n",
            "prompt_encoder.lstm_head.weight_hh_l1_reverse\n",
            "prompt_encoder.lstm_head.bias_hh_l1_reverse\n",
            "prompt_encoder.mlp_head.0.weight\n",
            "prompt_encoder.mlp_head.0.bias\n",
            "prompt_encoder.mlp_head.2.weight\n",
            "prompt_encoder.mlp_head.2.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(args.epochs):\n",
        "    total_loss = 0\n",
        "    sp_model.train()\n",
        "    avg_lm_loss = AverageMeter()\n",
        "    with tqdm(total = len(train_loader), desc=f\"Epoch {epoch + 1}/{args.epochs}\", position=0, leave=True, ncols=80) as progress_bar:\n",
        "        for idx, data in enumerate(train_loader):\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            data = {key: value for key, value in data.items()}\n",
        "            #print(torch.cuda.memory_summary())\n",
        "            _input = data['input'].to(args.device)\n",
        "            _target = data['target'].to(args.device)\n",
        "            _msk = data['mask'].to(args.device)\n",
        "            output = sp_model(\n",
        "                input_ids =_input, attention_mask=_msk, target = None\n",
        "            )\n",
        "            lm_logits= output[0]\n",
        "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
        "            shift_labels = _target[..., 1:].contiguous()\n",
        "            shift_logits = shift_logits[..., 6:, :].contiguous()\n",
        "            # Flatten the tokens\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            #print(\"Prompt embeddings after update:\", model.prompt_embeddings.weight.data)\n",
        "            torch.cuda.empty_cache()\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix_str(f\"Loss: {loss.item()}\")\n",
        "            progress_bar.update()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch + 1}/{args.epochs} - Average Loss: {avg_loss}\")"
      ],
      "metadata": {
        "id": "0GjM0Lp-uyZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b15ebc-38d6-49ca-b36c-64779cb69bfe"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██| 5258/5258 [28:18<00:00,  3.09it/s, Loss: 1.8207974433898926]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3 - Average Loss: 2.3861988005913815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██| 5258/5258 [28:10<00:00,  3.11it/s, Loss: 1.6014472246170044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3 - Average Loss: 2.0052692187109025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|███| 5258/5258 [28:17<00:00,  3.10it/s, Loss: 1.592934489250183]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3 - Average Loss: 1.8834533438613634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'sp_model_state_dict': sp_model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, '/content/drive/MyDrive/Differentially-Private-Fine-tuning-of-Language-Models-main/model_checkpoint.pth')"
      ],
      "metadata": {
        "id": "W9ZwHjt2eZ5D"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qd2O_ulgcLj",
        "outputId": "9444fdfb-6814-4b54-908e-7846c5d2c9ad"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "metadata": {
        "id": "1eXiwLt3bLw6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_model.eval()\n",
        "predictions = []\n",
        "references = []\n",
        "with torch.no_grad():\n",
        "    for idx, data in enumerate(valid_loader):\n",
        "        input_ids = data['input'].to(args.device)\n",
        "        target_ids = data['target'].to(args.device)\n",
        "        mask = data['mask'].to(args.device)\n",
        "\n",
        "        # Generate output using the model\n",
        "        outputs = sp_model(input_ids=input_ids, attention_mask=mask, target=None)\n",
        "        lm_logits = outputs[0]\n",
        "\n",
        "        # Convert logits to token ids\n",
        "        predicted_token_ids = torch.argmax(lm_logits, dim=-1)\n",
        "\n",
        "        # Detokenize or decode text here (depending on your tokenizer)\n",
        "        # This is an example; you'll need to replace it with your actual detokenization method\n",
        "        predicted_texts = [tokenizer.decode(ids) for ids in predicted_token_ids]\n",
        "        target_texts = [tokenizer.decode(ids) for ids in target_ids]\n",
        "\n",
        "        predictions.extend(predicted_texts)\n",
        "        references.extend([[text] for text in target_texts])  # Note that references should be a list of lists\n",
        "\n",
        "bleu_score = corpus_bleu(references, predictions)\n",
        "print(bleu_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJSW9HTqghvF",
        "outputId": "e4baac32-6bc6-47f4-d82c-0c76545e9862"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5632400320862083\n"
          ]
        }
      ]
    }
  ]
}